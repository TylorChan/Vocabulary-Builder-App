# Role-play learning rule
<!-- - 替代目前的复习模式
    - 先问video-context related的meaning
        - 用户不清楚的话，会多给些提示
    - 再问real life meaning
        - 用户不清楚的话，会多给些提示
    - 再问在video context的背景下，用该词组一个句子
        - 用户不清楚的话，会多给些提示
    - 再问real life context背景下，用该词组一个句子
        - 用户不清楚的话，会多给些提示
    - 然后Rater Agent通过关于该词的用户与Teacher Agent的对话来打分
    - 进行下一个词，循环上述操作 -->
- 先获取今天due day的词汇
- 构建一个专门，基于due day词汇，用于生产场景对话的agent
    - 不清楚gpt realtime够不够用？需不需要用到gpt5.2
- 在对话开始前，用上述的agent构建完整的场景对话细节。
    - 一个完整的对话内，有多个场景来串联这些due day词汇。设置多个场景的原因是，单个场景很难将不同context的词汇，有逻辑，流畅地串联一起。
- 整个复习流程利用上述agent生成的情节对话
    - 对话中，一定要以引导用户为主，但不要太刻意。
    - 如果用户回答得模凌两可，对话agent应该追问
        - 包含传统的词汇的definition追问
        - 给予用户提示如果用户不知道在该场景下用什么词
    - 要显示目前进行到哪个词汇
        - 词的进度是按照场景串起来的顺序进行。所以一开始是没有固定的顺序
            - 这也说明了场景串联一定要有逻辑和顺畅性
        - 每当用户完成个场景，要显示词组词组完成情况，也就是，要显示目前完成了哪些词汇。目前的interface 2中，词汇进度是固定的，每当完成一个，状态会从3/5变成4/5。但在新的role-play learning的复习下，一个场景可能覆盖到大于等于1个的词汇，所以状态可能是3/5变成5/5这样（在这个例子中， 一个场景复习了2个）。
            - 但这涉及到了Rater Agent打分的问题。在目前的interface中，因为是一次过一个词汇，所以每当一个词汇完成复习时，Rater Agent就会打分。
                - 但是如果是在新的role-play learning的复习模式中，频繁的打分会影响用户体验。但是不显示打分的话，会降低用户对这个multi-agent的可信度或者提高疑惑程度。
                - 所以基于上述情况，目前我认为最好的打分方式就是，当一个场景过完大于等1个词汇的时候，显示给这些词汇打分，然后快速过到下一个场景。真正的打分系统发生在background，因为给多个词汇打分可能需要一些时间。把打分系统设置在background中，可以有效防止堵塞对话流
                    - 评分像目前一样，存在前端，然后会话结束时，batch update，这个逻辑不用更改

